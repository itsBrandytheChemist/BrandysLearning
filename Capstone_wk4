#libraries
library("tidymodels")
library("tidyverse")
library("stringr")
library('glmnet')

#files and basic df
dataset_url <- "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/seoul_bike_sharing_converted_normalized.csv"
bike_sharing_df <- read_csv(dataset_url)
spec(bike_sharing_df)

bike_sharing_df <- bike_sharing_df %>% 
                   select(-DATE, -FUNCTIONING_DAY)

#linear fit
lm_spec <- linear_reg() %>%
  set_engine("lm") %>% 
  set_mode("regression")

set.seed(1234)
data_split <- initial_split(bike_sharing_df, prop = 4/5)
train_data <- training(data_split)
test_data <- testing(data_split)

ggplot(data = train_data, aes(RENTED_BIKE_COUNT, TEMPERATURE)) + 
    geom_point() 

# Plot the higher order polynomial fits
ggplot(data=train_data, aes(RENTED_BIKE_COUNT, TEMPERATURE)) + 
    geom_point() + 
    geom_smooth(method = "lm", formula = y ~ x, color="red") + 
    geom_smooth(method = "lm", formula = y ~ poly(x, 2), color="yellow") + 
    geom_smooth(method = "lm", formula = y ~ poly(x, 4), color="green") + 
    geom_smooth(method = "lm", formula = y ~ poly(x, 6), color="blue")

# Fit a linear model with higher order polynomial on some important variables 

# #HINT: Use ploy function to build polynomial terms, lm_poly <- RENTED_BIKE_COUNT ~ poly(TEMPERATURE, 6) + poly(HUMIDITY, 4) .....
lm_spec <- linear_reg() %>%
    set_engine(engine = 'lm')
lm_poly <- fit(lm_spec, RENTED_BIKE_COUNT ~ poly(RAINFALL, 4) + poly(HUMIDITY, 4) + poly(TEMPERATURE, 4) + `18` + 
               DEW_POINT_TEMPERATURE + `19` + `8` + `21` + `20` + `4` + `5` + AUTUMN + `3` + `22` + `17` + `2` + SOLAR_RADIATION + SNOWFALL +
               `11` + `10` + `6` + `12`, train_data)
summary(lm_poly$fit)

# Use predict() function to generate test results for `lm_poly`
test_poly_results <- lm_poly %>%
                        predict(new_data = test_data) %>%
                        mutate(truth = test_data$RENTED_BIKE_COUNT)
head(test_poly_results, 4)

test_poly_results[test_poly_results<0] <- 0

# Calculate R-squared and RMSE from the test results
rsq(test_poly_results, truth = truth, estimate = .pred)
rmse(test_poly_results, truth = truth, estimate = .pred)

# Add interaction terms to the poly regression built in previous step

# HINT: You could use `*` operator to create interaction terms such as HUMIDITY*TEMPERATURE and make the formula look like:
# RENTED_BIKE_COUNT ~ RAINFALL*HUMIDITY ...
lm_poly_inter <- fit(lm_spec, RENTED_BIKE_COUNT ~ poly(RAINFALL, 4) + poly(HUMIDITY, 4) + poly(TEMPERATURE, 4) + TEMPERATURE*HUMIDITY + WINTER*TEMPERATURE + RAINFALL*TEMPERATURE + `18` + 
               DEW_POINT_TEMPERATURE + `19` + `8` + `21` + `20` + `4` + `5` + AUTUMN + `3` + `22` + `17` + `2` + SOLAR_RADIATION + SNOWFALL +
               `11` + `10` + `6` + `12`, train_data)
summary(lm_poly_inter$fit)

# Calculate R-squared and RMSE for the new model to see if performance has improved
test_poly_inter_results <- lm_poly_inter %>%
                        predict(new_data = test_data) %>%
                        mutate(truth = test_data$RENTED_BIKE_COUNT)
head(test_poly_inter_results, 4)
test_poly_inter_results[test_poly_inter_results<0] <- 0
rsq(test_poly_inter_results, truth = truth, estimate = .pred)
rmse(test_poly_inter_results, truth = truth, estimate = .pred)


# HINT: Use linear_reg() function with two parameters: penalty and mixture
# - penalty controls the intensity of model regularization
# - mixture controls the tradeoff between L1 and L2 regularizations
glmnet_spec <- linear_reg(penalty = 0.1, mixture = 1) %>%
                set_engine('glmnet')

# You could manually try different parameter combinations or use grid search to find optimal combinations

#simplify recipe to all var, linear
start_recipe <- recipe(RENTED_BIKE_COUNT ~ ., data = train_data)

start_wf <- workflow() %>%
        add_recipe(start_recipe)

start_fit <- start_wf %>%
        add_model(glmnet_spec) %>%
        fit(data = train_data)

start_fit %>%
    pull_workflow_fit()%>%
    tidy()

